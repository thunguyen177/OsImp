{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90e3942",
   "metadata": {
    "id": "a90e3942"
   },
   "outputs": [],
   "source": [
    "import sklearn.neighbors._base\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "# !pip install impyute\n",
    "# !pip install fancyimpute\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "# import impyute as impy\n",
    "from fancyimpute import SoftImpute#, MatrixFactorization\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from missingpy import MissForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import norm, inv\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from fancyimpute import SimpleFill, SoftImpute\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.metrics import sensitivity_score\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from imblearn.datasets import fetch_datasets\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from functions.OsImp import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from functions.eval import *\n",
    "from functions.utils import *\n",
    "from functions.OsImp import *\n",
    "from functions.OsImp_star import *\n",
    "from functions.dpers import *\n",
    "from functions.dimv import dimv\n",
    "# imputer = dimv\n",
    "\n",
    "imputer = IterativeImputer().fit_transform\n",
    "# imputer = SoftImpute(convergence_threshold=0.1, max_iters=10).fit_transform\n",
    "# imputer = MissForest().fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22eff0aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22eff0aa",
    "outputId": "d34837e0-c9d8-482a-ee8b-31ff680a5d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(351, 32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data',\n",
    "                  sep = \",\", header = None)\n",
    "data.head()\n",
    "data = pd.DataFrame.to_numpy(data)\n",
    "X, y = data[:,:34].astype(np.float64), data[:,34]\n",
    "le2 = LabelEncoder()\n",
    "y = le2.fit_transform(y)\n",
    "G = len(np.unique(y))\n",
    "X = np.delete(X,[0,1], axis = 1)\n",
    "for g in range(G):\n",
    "  print(sum(y==g))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0501997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rates = np.array([0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "res_all = []\n",
    "for missing_rate in missing_rates:\n",
    "  K, nMC, result = 2, 10, []\n",
    "  n = np.array([100,-80])\n",
    "  res = np.asarray([get_all_res_star(X, y, i, n, K, G,imputer, missing_rate) for i in range(nMC)], dtype = object)\n",
    "  res = show_result(res)\n",
    "  res_all.append(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5697f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_tab = pd.concat((res_all[0][1][0], res_all[0][1][1], \n",
    "                        res_all[1][1][0], res_all[1][1][1], \n",
    "                        res_all[2][1][0], res_all[2][1][1], \n",
    "                        res_all[3][1][0], res_all[3][1][1], \n",
    "                        res_all[4][1][0], res_all[4][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84995a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NearMiss</th>\n",
       "      <th>kmeanSmt</th>\n",
       "      <th>SmtNN</th>\n",
       "      <th>SVMSmt</th>\n",
       "      <th>InsHard</th>\n",
       "      <th>OsImp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing rate</th>\n",
       "      <th>metric</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">50%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.755$\\pm$0.03</td>\n",
       "      <td>0.933$\\pm$0.015</td>\n",
       "      <td>0.925$\\pm$0.01</td>\n",
       "      <td>0.932$\\pm$0.017</td>\n",
       "      <td>0.856$\\pm$0.045</td>\n",
       "      <td>0.933$\\pm$0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.732$\\pm$0.06</td>\n",
       "      <td>0.827$\\pm$0.017</td>\n",
       "      <td>0.814$\\pm$0.033</td>\n",
       "      <td>0.825$\\pm$0.018</td>\n",
       "      <td>0.813$\\pm$0.041</td>\n",
       "      <td>0.823$\\pm$0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.681$\\pm$0.053</td>\n",
       "      <td>0.822$\\pm$0.041</td>\n",
       "      <td>0.82$\\pm$0.056</td>\n",
       "      <td>0.825$\\pm$0.037</td>\n",
       "      <td>0.74$\\pm$0.045</td>\n",
       "      <td>0.784$\\pm$0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.75$\\pm$0.033</td>\n",
       "      <td>0.933$\\pm$0.015</td>\n",
       "      <td>0.926$\\pm$0.01</td>\n",
       "      <td>0.932$\\pm$0.017</td>\n",
       "      <td>0.852$\\pm$0.048</td>\n",
       "      <td>0.933$\\pm$0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.729$\\pm$0.063</td>\n",
       "      <td>0.829$\\pm$0.014</td>\n",
       "      <td>0.818$\\pm$0.032</td>\n",
       "      <td>0.826$\\pm$0.017</td>\n",
       "      <td>0.813$\\pm$0.041</td>\n",
       "      <td>0.826$\\pm$0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.675$\\pm$0.054</td>\n",
       "      <td>0.821$\\pm$0.041</td>\n",
       "      <td>0.821$\\pm$0.055</td>\n",
       "      <td>0.823$\\pm$0.038</td>\n",
       "      <td>0.735$\\pm$0.047</td>\n",
       "      <td>0.782$\\pm$0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">60%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.703$\\pm$0.026</td>\n",
       "      <td>0.912$\\pm$0.032</td>\n",
       "      <td>0.896$\\pm$0.04</td>\n",
       "      <td>0.912$\\pm$0.025</td>\n",
       "      <td>0.822$\\pm$0.056</td>\n",
       "      <td>0.907$\\pm$0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.742$\\pm$0.075</td>\n",
       "      <td>0.808$\\pm$0.047</td>\n",
       "      <td>0.81$\\pm$0.039</td>\n",
       "      <td>0.801$\\pm$0.046</td>\n",
       "      <td>0.779$\\pm$0.073</td>\n",
       "      <td>0.825$\\pm$0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.684$\\pm$0.061</td>\n",
       "      <td>0.758$\\pm$0.046</td>\n",
       "      <td>0.766$\\pm$0.037</td>\n",
       "      <td>0.742$\\pm$0.067</td>\n",
       "      <td>0.686$\\pm$0.061</td>\n",
       "      <td>0.743$\\pm$0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.698$\\pm$0.025</td>\n",
       "      <td>0.911$\\pm$0.034</td>\n",
       "      <td>0.895$\\pm$0.042</td>\n",
       "      <td>0.911$\\pm$0.026</td>\n",
       "      <td>0.817$\\pm$0.057</td>\n",
       "      <td>0.906$\\pm$0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.738$\\pm$0.08</td>\n",
       "      <td>0.809$\\pm$0.048</td>\n",
       "      <td>0.811$\\pm$0.041</td>\n",
       "      <td>0.801$\\pm$0.047</td>\n",
       "      <td>0.777$\\pm$0.076</td>\n",
       "      <td>0.827$\\pm$0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.677$\\pm$0.061</td>\n",
       "      <td>0.755$\\pm$0.05</td>\n",
       "      <td>0.765$\\pm$0.039</td>\n",
       "      <td>0.74$\\pm$0.071</td>\n",
       "      <td>0.678$\\pm$0.062</td>\n",
       "      <td>0.741$\\pm$0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">70%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.698$\\pm$0.021</td>\n",
       "      <td>0.877$\\pm$0.034</td>\n",
       "      <td>0.814$\\pm$0.046</td>\n",
       "      <td>0.877$\\pm$0.03</td>\n",
       "      <td>0.713$\\pm$0.021</td>\n",
       "      <td>0.886$\\pm$0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.743$\\pm$0.044</td>\n",
       "      <td>0.802$\\pm$0.038</td>\n",
       "      <td>0.788$\\pm$0.03</td>\n",
       "      <td>0.807$\\pm$0.033</td>\n",
       "      <td>0.743$\\pm$0.041</td>\n",
       "      <td>0.8$\\pm$0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.69$\\pm$0.079</td>\n",
       "      <td>0.706$\\pm$0.063</td>\n",
       "      <td>0.753$\\pm$0.031</td>\n",
       "      <td>0.734$\\pm$0.037</td>\n",
       "      <td>0.687$\\pm$0.045</td>\n",
       "      <td>0.726$\\pm$0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.697$\\pm$0.023</td>\n",
       "      <td>0.876$\\pm$0.034</td>\n",
       "      <td>0.812$\\pm$0.047</td>\n",
       "      <td>0.876$\\pm$0.031</td>\n",
       "      <td>0.711$\\pm$0.022</td>\n",
       "      <td>0.884$\\pm$0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.743$\\pm$0.045</td>\n",
       "      <td>0.804$\\pm$0.039</td>\n",
       "      <td>0.79$\\pm$0.034</td>\n",
       "      <td>0.809$\\pm$0.034</td>\n",
       "      <td>0.742$\\pm$0.043</td>\n",
       "      <td>0.806$\\pm$0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.689$\\pm$0.076</td>\n",
       "      <td>0.711$\\pm$0.067</td>\n",
       "      <td>0.757$\\pm$0.035</td>\n",
       "      <td>0.734$\\pm$0.04</td>\n",
       "      <td>0.683$\\pm$0.042</td>\n",
       "      <td>0.73$\\pm$0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">80%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.681$\\pm$0.039</td>\n",
       "      <td>0.828$\\pm$0.051</td>\n",
       "      <td>0.71$\\pm$0.031</td>\n",
       "      <td>0.831$\\pm$0.047</td>\n",
       "      <td>0.705$\\pm$0.025</td>\n",
       "      <td>0.797$\\pm$0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.699$\\pm$0.047</td>\n",
       "      <td>0.785$\\pm$0.035</td>\n",
       "      <td>0.692$\\pm$0.053</td>\n",
       "      <td>0.784$\\pm$0.031</td>\n",
       "      <td>0.71$\\pm$0.06</td>\n",
       "      <td>0.798$\\pm$0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.59$\\pm$0.054</td>\n",
       "      <td>0.698$\\pm$0.072</td>\n",
       "      <td>0.658$\\pm$0.046</td>\n",
       "      <td>0.646$\\pm$0.083</td>\n",
       "      <td>0.649$\\pm$0.056</td>\n",
       "      <td>0.682$\\pm$0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.685$\\pm$0.034</td>\n",
       "      <td>0.825$\\pm$0.052</td>\n",
       "      <td>0.707$\\pm$0.031</td>\n",
       "      <td>0.828$\\pm$0.047</td>\n",
       "      <td>0.706$\\pm$0.022</td>\n",
       "      <td>0.794$\\pm$0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.695$\\pm$0.049</td>\n",
       "      <td>0.787$\\pm$0.036</td>\n",
       "      <td>0.688$\\pm$0.053</td>\n",
       "      <td>0.784$\\pm$0.034</td>\n",
       "      <td>0.706$\\pm$0.062</td>\n",
       "      <td>0.801$\\pm$0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.596$\\pm$0.041</td>\n",
       "      <td>0.696$\\pm$0.074</td>\n",
       "      <td>0.658$\\pm$0.051</td>\n",
       "      <td>0.643$\\pm$0.087</td>\n",
       "      <td>0.648$\\pm$0.057</td>\n",
       "      <td>0.683$\\pm$0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">90%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.597$\\pm$0.067</td>\n",
       "      <td>0.705$\\pm$0.052</td>\n",
       "      <td>0.507$\\pm$0.181</td>\n",
       "      <td>0.735$\\pm$0.032</td>\n",
       "      <td>0.66$\\pm$0.062</td>\n",
       "      <td>0.713$\\pm$0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.673$\\pm$0.076</td>\n",
       "      <td>0.631$\\pm$0.093</td>\n",
       "      <td>0.568$\\pm$0.085</td>\n",
       "      <td>0.68$\\pm$0.099</td>\n",
       "      <td>0.664$\\pm$0.085</td>\n",
       "      <td>0.71$\\pm$0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.525$\\pm$0.147</td>\n",
       "      <td>0.591$\\pm$0.095</td>\n",
       "      <td>0.582$\\pm$0.124</td>\n",
       "      <td>0.607$\\pm$0.068</td>\n",
       "      <td>0.557$\\pm$0.144</td>\n",
       "      <td>0.632$\\pm$0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.613$\\pm$0.05</td>\n",
       "      <td>0.703$\\pm$0.047</td>\n",
       "      <td>0.552$\\pm$0.119</td>\n",
       "      <td>0.73$\\pm$0.032</td>\n",
       "      <td>0.665$\\pm$0.054</td>\n",
       "      <td>0.707$\\pm$0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.672$\\pm$0.076</td>\n",
       "      <td>0.634$\\pm$0.097</td>\n",
       "      <td>0.57$\\pm$0.079</td>\n",
       "      <td>0.683$\\pm$0.103</td>\n",
       "      <td>0.664$\\pm$0.086</td>\n",
       "      <td>0.714$\\pm$0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.549$\\pm$0.113</td>\n",
       "      <td>0.589$\\pm$0.103</td>\n",
       "      <td>0.579$\\pm$0.116</td>\n",
       "      <td>0.606$\\pm$0.073</td>\n",
       "      <td>0.573$\\pm$0.114</td>\n",
       "      <td>0.638$\\pm$0.049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            NearMiss         kmeanSmt  \\\n",
       "missing rate metric      classifier                                     \n",
       "50%          F-1 score   SVM          0.755$\\pm$0.03  0.933$\\pm$0.015   \n",
       "                         LR           0.732$\\pm$0.06  0.827$\\pm$0.017   \n",
       "                         DCT         0.681$\\pm$0.053  0.822$\\pm$0.041   \n",
       "             sensitivity SVM          0.75$\\pm$0.033  0.933$\\pm$0.015   \n",
       "                         LR          0.729$\\pm$0.063  0.829$\\pm$0.014   \n",
       "                         DCT         0.675$\\pm$0.054  0.821$\\pm$0.041   \n",
       "60%          F-1 score   SVM         0.703$\\pm$0.026  0.912$\\pm$0.032   \n",
       "                         LR          0.742$\\pm$0.075  0.808$\\pm$0.047   \n",
       "                         DCT         0.684$\\pm$0.061  0.758$\\pm$0.046   \n",
       "             sensitivity SVM         0.698$\\pm$0.025  0.911$\\pm$0.034   \n",
       "                         LR           0.738$\\pm$0.08  0.809$\\pm$0.048   \n",
       "                         DCT         0.677$\\pm$0.061   0.755$\\pm$0.05   \n",
       "70%          F-1 score   SVM         0.698$\\pm$0.021  0.877$\\pm$0.034   \n",
       "                         LR          0.743$\\pm$0.044  0.802$\\pm$0.038   \n",
       "                         DCT          0.69$\\pm$0.079  0.706$\\pm$0.063   \n",
       "             sensitivity SVM         0.697$\\pm$0.023  0.876$\\pm$0.034   \n",
       "                         LR          0.743$\\pm$0.045  0.804$\\pm$0.039   \n",
       "                         DCT         0.689$\\pm$0.076  0.711$\\pm$0.067   \n",
       "80%          F-1 score   SVM         0.681$\\pm$0.039  0.828$\\pm$0.051   \n",
       "                         LR          0.699$\\pm$0.047  0.785$\\pm$0.035   \n",
       "                         DCT          0.59$\\pm$0.054  0.698$\\pm$0.072   \n",
       "             sensitivity SVM         0.685$\\pm$0.034  0.825$\\pm$0.052   \n",
       "                         LR          0.695$\\pm$0.049  0.787$\\pm$0.036   \n",
       "                         DCT         0.596$\\pm$0.041  0.696$\\pm$0.074   \n",
       "90%          F-1 score   SVM         0.597$\\pm$0.067  0.705$\\pm$0.052   \n",
       "                         LR          0.673$\\pm$0.076  0.631$\\pm$0.093   \n",
       "                         DCT         0.525$\\pm$0.147  0.591$\\pm$0.095   \n",
       "             sensitivity SVM          0.613$\\pm$0.05  0.703$\\pm$0.047   \n",
       "                         LR          0.672$\\pm$0.076  0.634$\\pm$0.097   \n",
       "                         DCT         0.549$\\pm$0.113  0.589$\\pm$0.103   \n",
       "\n",
       "                                               SmtNN           SVMSmt  \\\n",
       "missing rate metric      classifier                                     \n",
       "50%          F-1 score   SVM          0.925$\\pm$0.01  0.932$\\pm$0.017   \n",
       "                         LR          0.814$\\pm$0.033  0.825$\\pm$0.018   \n",
       "                         DCT          0.82$\\pm$0.056  0.825$\\pm$0.037   \n",
       "             sensitivity SVM          0.926$\\pm$0.01  0.932$\\pm$0.017   \n",
       "                         LR          0.818$\\pm$0.032  0.826$\\pm$0.017   \n",
       "                         DCT         0.821$\\pm$0.055  0.823$\\pm$0.038   \n",
       "60%          F-1 score   SVM          0.896$\\pm$0.04  0.912$\\pm$0.025   \n",
       "                         LR           0.81$\\pm$0.039  0.801$\\pm$0.046   \n",
       "                         DCT         0.766$\\pm$0.037  0.742$\\pm$0.067   \n",
       "             sensitivity SVM         0.895$\\pm$0.042  0.911$\\pm$0.026   \n",
       "                         LR          0.811$\\pm$0.041  0.801$\\pm$0.047   \n",
       "                         DCT         0.765$\\pm$0.039   0.74$\\pm$0.071   \n",
       "70%          F-1 score   SVM         0.814$\\pm$0.046   0.877$\\pm$0.03   \n",
       "                         LR           0.788$\\pm$0.03  0.807$\\pm$0.033   \n",
       "                         DCT         0.753$\\pm$0.031  0.734$\\pm$0.037   \n",
       "             sensitivity SVM         0.812$\\pm$0.047  0.876$\\pm$0.031   \n",
       "                         LR           0.79$\\pm$0.034  0.809$\\pm$0.034   \n",
       "                         DCT         0.757$\\pm$0.035   0.734$\\pm$0.04   \n",
       "80%          F-1 score   SVM          0.71$\\pm$0.031  0.831$\\pm$0.047   \n",
       "                         LR          0.692$\\pm$0.053  0.784$\\pm$0.031   \n",
       "                         DCT         0.658$\\pm$0.046  0.646$\\pm$0.083   \n",
       "             sensitivity SVM         0.707$\\pm$0.031  0.828$\\pm$0.047   \n",
       "                         LR          0.688$\\pm$0.053  0.784$\\pm$0.034   \n",
       "                         DCT         0.658$\\pm$0.051  0.643$\\pm$0.087   \n",
       "90%          F-1 score   SVM         0.507$\\pm$0.181  0.735$\\pm$0.032   \n",
       "                         LR          0.568$\\pm$0.085   0.68$\\pm$0.099   \n",
       "                         DCT         0.582$\\pm$0.124  0.607$\\pm$0.068   \n",
       "             sensitivity SVM         0.552$\\pm$0.119   0.73$\\pm$0.032   \n",
       "                         LR           0.57$\\pm$0.079  0.683$\\pm$0.103   \n",
       "                         DCT         0.579$\\pm$0.116  0.606$\\pm$0.073   \n",
       "\n",
       "                                             InsHard            OsImp  \n",
       "missing rate metric      classifier                                    \n",
       "50%          F-1 score   SVM         0.856$\\pm$0.045  0.933$\\pm$0.014  \n",
       "                         LR          0.813$\\pm$0.041  0.823$\\pm$0.026  \n",
       "                         DCT          0.74$\\pm$0.045  0.784$\\pm$0.036  \n",
       "             sensitivity SVM         0.852$\\pm$0.048  0.933$\\pm$0.014  \n",
       "                         LR          0.813$\\pm$0.041  0.826$\\pm$0.025  \n",
       "                         DCT         0.735$\\pm$0.047  0.782$\\pm$0.036  \n",
       "60%          F-1 score   SVM         0.822$\\pm$0.056   0.907$\\pm$0.03  \n",
       "                         LR          0.779$\\pm$0.073  0.825$\\pm$0.033  \n",
       "                         DCT         0.686$\\pm$0.061  0.743$\\pm$0.051  \n",
       "             sensitivity SVM         0.817$\\pm$0.057  0.906$\\pm$0.032  \n",
       "                         LR          0.777$\\pm$0.076  0.827$\\pm$0.035  \n",
       "                         DCT         0.678$\\pm$0.062  0.741$\\pm$0.057  \n",
       "70%          F-1 score   SVM         0.713$\\pm$0.021  0.886$\\pm$0.021  \n",
       "                         LR          0.743$\\pm$0.041    0.8$\\pm$0.042  \n",
       "                         DCT         0.687$\\pm$0.045  0.726$\\pm$0.059  \n",
       "             sensitivity SVM         0.711$\\pm$0.022  0.884$\\pm$0.022  \n",
       "                         LR          0.742$\\pm$0.043  0.806$\\pm$0.042  \n",
       "                         DCT         0.683$\\pm$0.042   0.73$\\pm$0.061  \n",
       "80%          F-1 score   SVM         0.705$\\pm$0.025  0.797$\\pm$0.046  \n",
       "                         LR            0.71$\\pm$0.06  0.798$\\pm$0.032  \n",
       "                         DCT         0.649$\\pm$0.056  0.682$\\pm$0.081  \n",
       "             sensitivity SVM         0.706$\\pm$0.022  0.794$\\pm$0.047  \n",
       "                         LR          0.706$\\pm$0.062  0.801$\\pm$0.031  \n",
       "                         DCT         0.648$\\pm$0.057  0.683$\\pm$0.083  \n",
       "90%          F-1 score   SVM          0.66$\\pm$0.062  0.713$\\pm$0.034  \n",
       "                         LR          0.664$\\pm$0.085   0.71$\\pm$0.075  \n",
       "                         DCT         0.557$\\pm$0.144  0.632$\\pm$0.048  \n",
       "             sensitivity SVM         0.665$\\pm$0.054  0.707$\\pm$0.037  \n",
       "                         LR          0.664$\\pm$0.086  0.714$\\pm$0.079  \n",
       "                         DCT         0.573$\\pm$0.114  0.638$\\pm$0.049  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftindex = pd.MultiIndex.from_product([[\"50%\", \"60%\", \"70%\", \"80%\", \"90%\"],\n",
    "                                        [\"F-1 score\",\"sensitivity\"], \n",
    "                                        [\"SVM\", \"LR\", \"DCT\"]], \n",
    "                                       names = [\"missing rate\", \"metric\", \"classifier\"])\n",
    "all_res = pd.DataFrame(concat_tab.to_numpy(), index = leftindex, columns = concat_tab.columns)\n",
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60280e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_to_export = pd.concat((res_all[0][0][0][0], res_all[0][0][0][1], \n",
    "                        res_all[1][0][0][0], res_all[1][0][0][1], \n",
    "                        res_all[2][0][0][0], res_all[2][0][0][1], \n",
    "                        res_all[3][0][0][0], res_all[3][0][0][1], \n",
    "                        res_all[4][0][0][0], res_all[4][0][0][1]))\n",
    "concat_to_export.to_csv(\"mean_f1_sensi_Inosphere_high.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9712ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "    &             &     &         NearMiss &         kmeanSmt &            SmtNN &           SVMSmt &          InsHard &            OsImp \\\\\n",
      "missing rate & metric & classifier &                  &                  &                  &                  &                  &                  \\\\\n",
      "\\midrule\n",
      "50\\% & F-1 score & SVM &   0.755\\$\\textbackslash pm\\$0.03 &  0.933\\$\\textbackslash pm\\$0.015 &   0.925\\$\\textbackslash pm\\$0.01 &  0.932\\$\\textbackslash pm\\$0.017 &  0.856\\$\\textbackslash pm\\$0.045 &  0.933\\$\\textbackslash pm\\$0.014 \\\\\n",
      "    &             & LR &   0.732\\$\\textbackslash pm\\$0.06 &  0.827\\$\\textbackslash pm\\$0.017 &  0.814\\$\\textbackslash pm\\$0.033 &  0.825\\$\\textbackslash pm\\$0.018 &  0.813\\$\\textbackslash pm\\$0.041 &  0.823\\$\\textbackslash pm\\$0.026 \\\\\n",
      "    &             & DCT &  0.681\\$\\textbackslash pm\\$0.053 &  0.822\\$\\textbackslash pm\\$0.041 &   0.82\\$\\textbackslash pm\\$0.056 &  0.825\\$\\textbackslash pm\\$0.037 &   0.74\\$\\textbackslash pm\\$0.045 &  0.784\\$\\textbackslash pm\\$0.036 \\\\\n",
      "    & sensitivity & SVM &   0.75\\$\\textbackslash pm\\$0.033 &  0.933\\$\\textbackslash pm\\$0.015 &   0.926\\$\\textbackslash pm\\$0.01 &  0.932\\$\\textbackslash pm\\$0.017 &  0.852\\$\\textbackslash pm\\$0.048 &  0.933\\$\\textbackslash pm\\$0.014 \\\\\n",
      "    &             & LR &  0.729\\$\\textbackslash pm\\$0.063 &  0.829\\$\\textbackslash pm\\$0.014 &  0.818\\$\\textbackslash pm\\$0.032 &  0.826\\$\\textbackslash pm\\$0.017 &  0.813\\$\\textbackslash pm\\$0.041 &  0.826\\$\\textbackslash pm\\$0.025 \\\\\n",
      "    &             & DCT &  0.675\\$\\textbackslash pm\\$0.054 &  0.821\\$\\textbackslash pm\\$0.041 &  0.821\\$\\textbackslash pm\\$0.055 &  0.823\\$\\textbackslash pm\\$0.038 &  0.735\\$\\textbackslash pm\\$0.047 &  0.782\\$\\textbackslash pm\\$0.036 \\\\\n",
      "60\\% & F-1 score & SVM &  0.703\\$\\textbackslash pm\\$0.026 &  0.912\\$\\textbackslash pm\\$0.032 &   0.896\\$\\textbackslash pm\\$0.04 &  0.912\\$\\textbackslash pm\\$0.025 &  0.822\\$\\textbackslash pm\\$0.056 &   0.907\\$\\textbackslash pm\\$0.03 \\\\\n",
      "    &             & LR &  0.742\\$\\textbackslash pm\\$0.075 &  0.808\\$\\textbackslash pm\\$0.047 &   0.81\\$\\textbackslash pm\\$0.039 &  0.801\\$\\textbackslash pm\\$0.046 &  0.779\\$\\textbackslash pm\\$0.073 &  0.825\\$\\textbackslash pm\\$0.033 \\\\\n",
      "    &             & DCT &  0.684\\$\\textbackslash pm\\$0.061 &  0.758\\$\\textbackslash pm\\$0.046 &  0.766\\$\\textbackslash pm\\$0.037 &  0.742\\$\\textbackslash pm\\$0.067 &  0.686\\$\\textbackslash pm\\$0.061 &  0.743\\$\\textbackslash pm\\$0.051 \\\\\n",
      "    & sensitivity & SVM &  0.698\\$\\textbackslash pm\\$0.025 &  0.911\\$\\textbackslash pm\\$0.034 &  0.895\\$\\textbackslash pm\\$0.042 &  0.911\\$\\textbackslash pm\\$0.026 &  0.817\\$\\textbackslash pm\\$0.057 &  0.906\\$\\textbackslash pm\\$0.032 \\\\\n",
      "    &             & LR &   0.738\\$\\textbackslash pm\\$0.08 &  0.809\\$\\textbackslash pm\\$0.048 &  0.811\\$\\textbackslash pm\\$0.041 &  0.801\\$\\textbackslash pm\\$0.047 &  0.777\\$\\textbackslash pm\\$0.076 &  0.827\\$\\textbackslash pm\\$0.035 \\\\\n",
      "    &             & DCT &  0.677\\$\\textbackslash pm\\$0.061 &   0.755\\$\\textbackslash pm\\$0.05 &  0.765\\$\\textbackslash pm\\$0.039 &   0.74\\$\\textbackslash pm\\$0.071 &  0.678\\$\\textbackslash pm\\$0.062 &  0.741\\$\\textbackslash pm\\$0.057 \\\\\n",
      "70\\% & F-1 score & SVM &  0.698\\$\\textbackslash pm\\$0.021 &  0.877\\$\\textbackslash pm\\$0.034 &  0.814\\$\\textbackslash pm\\$0.046 &   0.877\\$\\textbackslash pm\\$0.03 &  0.713\\$\\textbackslash pm\\$0.021 &  0.886\\$\\textbackslash pm\\$0.021 \\\\\n",
      "    &             & LR &  0.743\\$\\textbackslash pm\\$0.044 &  0.802\\$\\textbackslash pm\\$0.038 &   0.788\\$\\textbackslash pm\\$0.03 &  0.807\\$\\textbackslash pm\\$0.033 &  0.743\\$\\textbackslash pm\\$0.041 &    0.8\\$\\textbackslash pm\\$0.042 \\\\\n",
      "    &             & DCT &   0.69\\$\\textbackslash pm\\$0.079 &  0.706\\$\\textbackslash pm\\$0.063 &  0.753\\$\\textbackslash pm\\$0.031 &  0.734\\$\\textbackslash pm\\$0.037 &  0.687\\$\\textbackslash pm\\$0.045 &  0.726\\$\\textbackslash pm\\$0.059 \\\\\n",
      "    & sensitivity & SVM &  0.697\\$\\textbackslash pm\\$0.023 &  0.876\\$\\textbackslash pm\\$0.034 &  0.812\\$\\textbackslash pm\\$0.047 &  0.876\\$\\textbackslash pm\\$0.031 &  0.711\\$\\textbackslash pm\\$0.022 &  0.884\\$\\textbackslash pm\\$0.022 \\\\\n",
      "    &             & LR &  0.743\\$\\textbackslash pm\\$0.045 &  0.804\\$\\textbackslash pm\\$0.039 &   0.79\\$\\textbackslash pm\\$0.034 &  0.809\\$\\textbackslash pm\\$0.034 &  0.742\\$\\textbackslash pm\\$0.043 &  0.806\\$\\textbackslash pm\\$0.042 \\\\\n",
      "    &             & DCT &  0.689\\$\\textbackslash pm\\$0.076 &  0.711\\$\\textbackslash pm\\$0.067 &  0.757\\$\\textbackslash pm\\$0.035 &   0.734\\$\\textbackslash pm\\$0.04 &  0.683\\$\\textbackslash pm\\$0.042 &   0.73\\$\\textbackslash pm\\$0.061 \\\\\n",
      "80\\% & F-1 score & SVM &  0.681\\$\\textbackslash pm\\$0.039 &  0.828\\$\\textbackslash pm\\$0.051 &   0.71\\$\\textbackslash pm\\$0.031 &  0.831\\$\\textbackslash pm\\$0.047 &  0.705\\$\\textbackslash pm\\$0.025 &  0.797\\$\\textbackslash pm\\$0.046 \\\\\n",
      "    &             & LR &  0.699\\$\\textbackslash pm\\$0.047 &  0.785\\$\\textbackslash pm\\$0.035 &  0.692\\$\\textbackslash pm\\$0.053 &  0.784\\$\\textbackslash pm\\$0.031 &    0.71\\$\\textbackslash pm\\$0.06 &  0.798\\$\\textbackslash pm\\$0.032 \\\\\n",
      "    &             & DCT &   0.59\\$\\textbackslash pm\\$0.054 &  0.698\\$\\textbackslash pm\\$0.072 &  0.658\\$\\textbackslash pm\\$0.046 &  0.646\\$\\textbackslash pm\\$0.083 &  0.649\\$\\textbackslash pm\\$0.056 &  0.682\\$\\textbackslash pm\\$0.081 \\\\\n",
      "    & sensitivity & SVM &  0.685\\$\\textbackslash pm\\$0.034 &  0.825\\$\\textbackslash pm\\$0.052 &  0.707\\$\\textbackslash pm\\$0.031 &  0.828\\$\\textbackslash pm\\$0.047 &  0.706\\$\\textbackslash pm\\$0.022 &  0.794\\$\\textbackslash pm\\$0.047 \\\\\n",
      "    &             & LR &  0.695\\$\\textbackslash pm\\$0.049 &  0.787\\$\\textbackslash pm\\$0.036 &  0.688\\$\\textbackslash pm\\$0.053 &  0.784\\$\\textbackslash pm\\$0.034 &  0.706\\$\\textbackslash pm\\$0.062 &  0.801\\$\\textbackslash pm\\$0.031 \\\\\n",
      "    &             & DCT &  0.596\\$\\textbackslash pm\\$0.041 &  0.696\\$\\textbackslash pm\\$0.074 &  0.658\\$\\textbackslash pm\\$0.051 &  0.643\\$\\textbackslash pm\\$0.087 &  0.648\\$\\textbackslash pm\\$0.057 &  0.683\\$\\textbackslash pm\\$0.083 \\\\\n",
      "90\\% & F-1 score & SVM &  0.597\\$\\textbackslash pm\\$0.067 &  0.705\\$\\textbackslash pm\\$0.052 &  0.507\\$\\textbackslash pm\\$0.181 &  0.735\\$\\textbackslash pm\\$0.032 &   0.66\\$\\textbackslash pm\\$0.062 &  0.713\\$\\textbackslash pm\\$0.034 \\\\\n",
      "    &             & LR &  0.673\\$\\textbackslash pm\\$0.076 &  0.631\\$\\textbackslash pm\\$0.093 &  0.568\\$\\textbackslash pm\\$0.085 &   0.68\\$\\textbackslash pm\\$0.099 &  0.664\\$\\textbackslash pm\\$0.085 &   0.71\\$\\textbackslash pm\\$0.075 \\\\\n",
      "    &             & DCT &  0.525\\$\\textbackslash pm\\$0.147 &  0.591\\$\\textbackslash pm\\$0.095 &  0.582\\$\\textbackslash pm\\$0.124 &  0.607\\$\\textbackslash pm\\$0.068 &  0.557\\$\\textbackslash pm\\$0.144 &  0.632\\$\\textbackslash pm\\$0.048 \\\\\n",
      "    & sensitivity & SVM &   0.613\\$\\textbackslash pm\\$0.05 &  0.703\\$\\textbackslash pm\\$0.047 &  0.552\\$\\textbackslash pm\\$0.119 &   0.73\\$\\textbackslash pm\\$0.032 &  0.665\\$\\textbackslash pm\\$0.054 &  0.707\\$\\textbackslash pm\\$0.037 \\\\\n",
      "    &             & LR &  0.672\\$\\textbackslash pm\\$0.076 &  0.634\\$\\textbackslash pm\\$0.097 &   0.57\\$\\textbackslash pm\\$0.079 &  0.683\\$\\textbackslash pm\\$0.103 &  0.664\\$\\textbackslash pm\\$0.086 &  0.714\\$\\textbackslash pm\\$0.079 \\\\\n",
      "    &             & DCT &  0.549\\$\\textbackslash pm\\$0.113 &  0.589\\$\\textbackslash pm\\$0.103 &  0.579\\$\\textbackslash pm\\$0.116 &  0.606\\$\\textbackslash pm\\$0.073 &  0.573\\$\\textbackslash pm\\$0.114 &  0.638\\$\\textbackslash pm\\$0.049 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_res.to_latex(index = True, \n",
    "                       formatters = {\"name\": str.upper},\n",
    "                      float_format = \"{.1f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfde6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
