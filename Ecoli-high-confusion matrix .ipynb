{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90e3942",
   "metadata": {
    "id": "a90e3942"
   },
   "outputs": [],
   "source": [
    "import sklearn.neighbors._base\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "# !pip install impyute\n",
    "# !pip install fancyimpute\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "# import impyute as impy\n",
    "from fancyimpute import SoftImpute#, MatrixFactorization\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from missingpy import MissForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import norm, inv\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from fancyimpute import SimpleFill, SoftImpute\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.metrics import sensitivity_score\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from imblearn.datasets import fetch_datasets\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from functions.OsImp import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from functions.eval import *\n",
    "from functions.utils import *\n",
    "from functions.OsImp import *\n",
    "from functions.OsImp_star import *\n",
    "from functions.dpers import *\n",
    "from functions.dimv import dimv\n",
    "# imputer = dimv\n",
    "\n",
    "imputer = IterativeImputer().fit_transform\n",
    "# imputer = SoftImpute(convergence_threshold=0.1, max_iters=10).fit_transform\n",
    "# imputer = MissForest().fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22eff0aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22eff0aa",
    "outputId": "d34837e0-c9d8-482a-ee8b-31ff680a5d44",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, 7) 2 144.48 16.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49, 0.29, 0.48, 0.5 , 0.56, 0.24, 0.35],\n",
       "       [0.07, 0.4 , 0.48, 0.5 , 0.54, 0.35, 0.44],\n",
       "       [0.56, 0.4 , 0.48, 0.5 , 0.49, 0.37, 0.46]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  df = fetch_datasets()['ecoli']\n",
    "  X, y = df.data, df.target\n",
    "  le = LabelEncoder()\n",
    "  y = le.fit_transform(y)\n",
    "  G = len(np.unique(y))\n",
    "  print(np.shape(X), G, sum(y==0)*.6*.8, sum(y==1)*.6*.8)\n",
    "  X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0501997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rates = np.array([0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "res_all = []\n",
    "for missing_rate in missing_rates:\n",
    "  K, nMC, result = 2, 10, []\n",
    "  n = np.array([-90,80])\n",
    "  res = np.asarray([get_all_res_star(X, y, i, n, K, G,imputer, missing_rate) for i in range(nMC)], dtype = object)\n",
    "  res = show_result(res)\n",
    "  res_all.append(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5697f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_tab = pd.concat((res_all[0][1][0], res_all[0][1][1], \n",
    "                        res_all[1][1][0], res_all[1][1][1], \n",
    "                        res_all[2][1][0], res_all[2][1][1], \n",
    "                        res_all[3][1][0], res_all[3][1][1], \n",
    "                        res_all[4][1][0], res_all[4][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84995a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NearMiss</th>\n",
       "      <th>kmeanSmt</th>\n",
       "      <th>SmtNN</th>\n",
       "      <th>SVMSmt</th>\n",
       "      <th>InsHard</th>\n",
       "      <th>OsImp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing rate</th>\n",
       "      <th>metric</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">50%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.627$\\pm$0.085</td>\n",
       "      <td>0.885$\\pm$0.02</td>\n",
       "      <td>0.866$\\pm$0.03</td>\n",
       "      <td>0.894$\\pm$0.032</td>\n",
       "      <td>0.791$\\pm$0.041</td>\n",
       "      <td>0.899$\\pm$0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.792$\\pm$0.071</td>\n",
       "      <td>0.856$\\pm$0.022</td>\n",
       "      <td>0.827$\\pm$0.036</td>\n",
       "      <td>0.882$\\pm$0.027</td>\n",
       "      <td>0.778$\\pm$0.037</td>\n",
       "      <td>0.88$\\pm$0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.502$\\pm$0.193</td>\n",
       "      <td>0.849$\\pm$0.035</td>\n",
       "      <td>0.842$\\pm$0.048</td>\n",
       "      <td>0.885$\\pm$0.028</td>\n",
       "      <td>0.758$\\pm$0.057</td>\n",
       "      <td>0.882$\\pm$0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.55$\\pm$0.091</td>\n",
       "      <td>0.87$\\pm$0.028</td>\n",
       "      <td>0.841$\\pm$0.037</td>\n",
       "      <td>0.882$\\pm$0.04</td>\n",
       "      <td>0.742$\\pm$0.057</td>\n",
       "      <td>0.884$\\pm$0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.746$\\pm$0.087</td>\n",
       "      <td>0.827$\\pm$0.029</td>\n",
       "      <td>0.789$\\pm$0.049</td>\n",
       "      <td>0.862$\\pm$0.036</td>\n",
       "      <td>0.725$\\pm$0.05</td>\n",
       "      <td>0.859$\\pm$0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.44$\\pm$0.187</td>\n",
       "      <td>0.845$\\pm$0.043</td>\n",
       "      <td>0.818$\\pm$0.067</td>\n",
       "      <td>0.878$\\pm$0.031</td>\n",
       "      <td>0.701$\\pm$0.073</td>\n",
       "      <td>0.879$\\pm$0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">60%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.65$\\pm$0.077</td>\n",
       "      <td>0.884$\\pm$0.024</td>\n",
       "      <td>0.863$\\pm$0.027</td>\n",
       "      <td>0.897$\\pm$0.035</td>\n",
       "      <td>0.784$\\pm$0.051</td>\n",
       "      <td>0.901$\\pm$0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.812$\\pm$0.034</td>\n",
       "      <td>0.856$\\pm$0.036</td>\n",
       "      <td>0.833$\\pm$0.027</td>\n",
       "      <td>0.883$\\pm$0.031</td>\n",
       "      <td>0.784$\\pm$0.042</td>\n",
       "      <td>0.872$\\pm$0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.528$\\pm$0.231</td>\n",
       "      <td>0.868$\\pm$0.038</td>\n",
       "      <td>0.824$\\pm$0.043</td>\n",
       "      <td>0.872$\\pm$0.047</td>\n",
       "      <td>0.725$\\pm$0.082</td>\n",
       "      <td>0.889$\\pm$0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.573$\\pm$0.087</td>\n",
       "      <td>0.865$\\pm$0.033</td>\n",
       "      <td>0.833$\\pm$0.035</td>\n",
       "      <td>0.884$\\pm$0.042</td>\n",
       "      <td>0.729$\\pm$0.072</td>\n",
       "      <td>0.885$\\pm$0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.764$\\pm$0.052</td>\n",
       "      <td>0.824$\\pm$0.05</td>\n",
       "      <td>0.793$\\pm$0.036</td>\n",
       "      <td>0.859$\\pm$0.044</td>\n",
       "      <td>0.728$\\pm$0.065</td>\n",
       "      <td>0.844$\\pm$0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.477$\\pm$0.22</td>\n",
       "      <td>0.867$\\pm$0.029</td>\n",
       "      <td>0.791$\\pm$0.06</td>\n",
       "      <td>0.864$\\pm$0.047</td>\n",
       "      <td>0.659$\\pm$0.105</td>\n",
       "      <td>0.892$\\pm$0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">70%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.666$\\pm$0.069</td>\n",
       "      <td>0.83$\\pm$0.029</td>\n",
       "      <td>0.835$\\pm$0.019</td>\n",
       "      <td>0.855$\\pm$0.024</td>\n",
       "      <td>0.75$\\pm$0.054</td>\n",
       "      <td>0.88$\\pm$0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.783$\\pm$0.038</td>\n",
       "      <td>0.821$\\pm$0.026</td>\n",
       "      <td>0.799$\\pm$0.031</td>\n",
       "      <td>0.857$\\pm$0.031</td>\n",
       "      <td>0.747$\\pm$0.057</td>\n",
       "      <td>0.842$\\pm$0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.554$\\pm$0.289</td>\n",
       "      <td>0.845$\\pm$0.027</td>\n",
       "      <td>0.817$\\pm$0.037</td>\n",
       "      <td>0.851$\\pm$0.032</td>\n",
       "      <td>0.687$\\pm$0.108</td>\n",
       "      <td>0.859$\\pm$0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.589$\\pm$0.076</td>\n",
       "      <td>0.8$\\pm$0.035</td>\n",
       "      <td>0.796$\\pm$0.024</td>\n",
       "      <td>0.836$\\pm$0.033</td>\n",
       "      <td>0.686$\\pm$0.068</td>\n",
       "      <td>0.867$\\pm$0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.727$\\pm$0.049</td>\n",
       "      <td>0.779$\\pm$0.032</td>\n",
       "      <td>0.748$\\pm$0.039</td>\n",
       "      <td>0.827$\\pm$0.037</td>\n",
       "      <td>0.683$\\pm$0.072</td>\n",
       "      <td>0.807$\\pm$0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.516$\\pm$0.242</td>\n",
       "      <td>0.827$\\pm$0.037</td>\n",
       "      <td>0.782$\\pm$0.06</td>\n",
       "      <td>0.849$\\pm$0.04</td>\n",
       "      <td>0.616$\\pm$0.13</td>\n",
       "      <td>0.856$\\pm$0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">80%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.674$\\pm$0.048</td>\n",
       "      <td>0.855$\\pm$0.041</td>\n",
       "      <td>0.843$\\pm$0.034</td>\n",
       "      <td>0.859$\\pm$0.04</td>\n",
       "      <td>0.738$\\pm$0.051</td>\n",
       "      <td>0.896$\\pm$0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.763$\\pm$0.044</td>\n",
       "      <td>0.829$\\pm$0.044</td>\n",
       "      <td>0.815$\\pm$0.035</td>\n",
       "      <td>0.852$\\pm$0.038</td>\n",
       "      <td>0.718$\\pm$0.063</td>\n",
       "      <td>0.848$\\pm$0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.372$\\pm$0.213</td>\n",
       "      <td>0.836$\\pm$0.056</td>\n",
       "      <td>0.816$\\pm$0.033</td>\n",
       "      <td>0.817$\\pm$0.048</td>\n",
       "      <td>0.678$\\pm$0.121</td>\n",
       "      <td>0.83$\\pm$0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.602$\\pm$0.052</td>\n",
       "      <td>0.847$\\pm$0.034</td>\n",
       "      <td>0.83$\\pm$0.041</td>\n",
       "      <td>0.881$\\pm$0.024</td>\n",
       "      <td>0.676$\\pm$0.06</td>\n",
       "      <td>0.888$\\pm$0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.707$\\pm$0.052</td>\n",
       "      <td>0.796$\\pm$0.06</td>\n",
       "      <td>0.773$\\pm$0.043</td>\n",
       "      <td>0.827$\\pm$0.052</td>\n",
       "      <td>0.653$\\pm$0.079</td>\n",
       "      <td>0.816$\\pm$0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.34$\\pm$0.16</td>\n",
       "      <td>0.822$\\pm$0.059</td>\n",
       "      <td>0.796$\\pm$0.045</td>\n",
       "      <td>0.807$\\pm$0.056</td>\n",
       "      <td>0.619$\\pm$0.152</td>\n",
       "      <td>0.841$\\pm$0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">90%</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">F-1 score</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.684$\\pm$0.097</td>\n",
       "      <td>0.833$\\pm$0.028</td>\n",
       "      <td>0.814$\\pm$0.061</td>\n",
       "      <td>0.836$\\pm$0.027</td>\n",
       "      <td>0.661$\\pm$0.184</td>\n",
       "      <td>0.853$\\pm$0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.705$\\pm$0.107</td>\n",
       "      <td>0.802$\\pm$0.021</td>\n",
       "      <td>0.824$\\pm$0.057</td>\n",
       "      <td>0.834$\\pm$0.031</td>\n",
       "      <td>0.621$\\pm$0.158</td>\n",
       "      <td>0.839$\\pm$0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.546$\\pm$0.233</td>\n",
       "      <td>0.813$\\pm$0.06</td>\n",
       "      <td>0.769$\\pm$0.093</td>\n",
       "      <td>0.786$\\pm$0.065</td>\n",
       "      <td>0.68$\\pm$0.088</td>\n",
       "      <td>0.829$\\pm$0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">sensitivity</th>\n",
       "      <th>SVM</th>\n",
       "      <td>0.618$\\pm$0.11</td>\n",
       "      <td>0.84$\\pm$0.053</td>\n",
       "      <td>0.806$\\pm$0.093</td>\n",
       "      <td>0.85$\\pm$0.057</td>\n",
       "      <td>0.613$\\pm$0.193</td>\n",
       "      <td>0.876$\\pm$0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.644$\\pm$0.121</td>\n",
       "      <td>0.782$\\pm$0.046</td>\n",
       "      <td>0.804$\\pm$0.079</td>\n",
       "      <td>0.825$\\pm$0.054</td>\n",
       "      <td>0.557$\\pm$0.168</td>\n",
       "      <td>0.827$\\pm$0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCT</th>\n",
       "      <td>0.497$\\pm$0.201</td>\n",
       "      <td>0.814$\\pm$0.093</td>\n",
       "      <td>0.744$\\pm$0.121</td>\n",
       "      <td>0.776$\\pm$0.107</td>\n",
       "      <td>0.614$\\pm$0.104</td>\n",
       "      <td>0.819$\\pm$0.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            NearMiss         kmeanSmt  \\\n",
       "missing rate metric      classifier                                     \n",
       "50%          F-1 score   SVM         0.627$\\pm$0.085   0.885$\\pm$0.02   \n",
       "                         LR          0.792$\\pm$0.071  0.856$\\pm$0.022   \n",
       "                         DCT         0.502$\\pm$0.193  0.849$\\pm$0.035   \n",
       "             sensitivity SVM          0.55$\\pm$0.091   0.87$\\pm$0.028   \n",
       "                         LR          0.746$\\pm$0.087  0.827$\\pm$0.029   \n",
       "                         DCT          0.44$\\pm$0.187  0.845$\\pm$0.043   \n",
       "60%          F-1 score   SVM          0.65$\\pm$0.077  0.884$\\pm$0.024   \n",
       "                         LR          0.812$\\pm$0.034  0.856$\\pm$0.036   \n",
       "                         DCT         0.528$\\pm$0.231  0.868$\\pm$0.038   \n",
       "             sensitivity SVM         0.573$\\pm$0.087  0.865$\\pm$0.033   \n",
       "                         LR          0.764$\\pm$0.052   0.824$\\pm$0.05   \n",
       "                         DCT          0.477$\\pm$0.22  0.867$\\pm$0.029   \n",
       "70%          F-1 score   SVM         0.666$\\pm$0.069   0.83$\\pm$0.029   \n",
       "                         LR          0.783$\\pm$0.038  0.821$\\pm$0.026   \n",
       "                         DCT         0.554$\\pm$0.289  0.845$\\pm$0.027   \n",
       "             sensitivity SVM         0.589$\\pm$0.076    0.8$\\pm$0.035   \n",
       "                         LR          0.727$\\pm$0.049  0.779$\\pm$0.032   \n",
       "                         DCT         0.516$\\pm$0.242  0.827$\\pm$0.037   \n",
       "80%          F-1 score   SVM         0.674$\\pm$0.048  0.855$\\pm$0.041   \n",
       "                         LR          0.763$\\pm$0.044  0.829$\\pm$0.044   \n",
       "                         DCT         0.372$\\pm$0.213  0.836$\\pm$0.056   \n",
       "             sensitivity SVM         0.602$\\pm$0.052  0.847$\\pm$0.034   \n",
       "                         LR          0.707$\\pm$0.052   0.796$\\pm$0.06   \n",
       "                         DCT           0.34$\\pm$0.16  0.822$\\pm$0.059   \n",
       "90%          F-1 score   SVM         0.684$\\pm$0.097  0.833$\\pm$0.028   \n",
       "                         LR          0.705$\\pm$0.107  0.802$\\pm$0.021   \n",
       "                         DCT         0.546$\\pm$0.233   0.813$\\pm$0.06   \n",
       "             sensitivity SVM          0.618$\\pm$0.11   0.84$\\pm$0.053   \n",
       "                         LR          0.644$\\pm$0.121  0.782$\\pm$0.046   \n",
       "                         DCT         0.497$\\pm$0.201  0.814$\\pm$0.093   \n",
       "\n",
       "                                               SmtNN           SVMSmt  \\\n",
       "missing rate metric      classifier                                     \n",
       "50%          F-1 score   SVM          0.866$\\pm$0.03  0.894$\\pm$0.032   \n",
       "                         LR          0.827$\\pm$0.036  0.882$\\pm$0.027   \n",
       "                         DCT         0.842$\\pm$0.048  0.885$\\pm$0.028   \n",
       "             sensitivity SVM         0.841$\\pm$0.037   0.882$\\pm$0.04   \n",
       "                         LR          0.789$\\pm$0.049  0.862$\\pm$0.036   \n",
       "                         DCT         0.818$\\pm$0.067  0.878$\\pm$0.031   \n",
       "60%          F-1 score   SVM         0.863$\\pm$0.027  0.897$\\pm$0.035   \n",
       "                         LR          0.833$\\pm$0.027  0.883$\\pm$0.031   \n",
       "                         DCT         0.824$\\pm$0.043  0.872$\\pm$0.047   \n",
       "             sensitivity SVM         0.833$\\pm$0.035  0.884$\\pm$0.042   \n",
       "                         LR          0.793$\\pm$0.036  0.859$\\pm$0.044   \n",
       "                         DCT          0.791$\\pm$0.06  0.864$\\pm$0.047   \n",
       "70%          F-1 score   SVM         0.835$\\pm$0.019  0.855$\\pm$0.024   \n",
       "                         LR          0.799$\\pm$0.031  0.857$\\pm$0.031   \n",
       "                         DCT         0.817$\\pm$0.037  0.851$\\pm$0.032   \n",
       "             sensitivity SVM         0.796$\\pm$0.024  0.836$\\pm$0.033   \n",
       "                         LR          0.748$\\pm$0.039  0.827$\\pm$0.037   \n",
       "                         DCT          0.782$\\pm$0.06   0.849$\\pm$0.04   \n",
       "80%          F-1 score   SVM         0.843$\\pm$0.034   0.859$\\pm$0.04   \n",
       "                         LR          0.815$\\pm$0.035  0.852$\\pm$0.038   \n",
       "                         DCT         0.816$\\pm$0.033  0.817$\\pm$0.048   \n",
       "             sensitivity SVM          0.83$\\pm$0.041  0.881$\\pm$0.024   \n",
       "                         LR          0.773$\\pm$0.043  0.827$\\pm$0.052   \n",
       "                         DCT         0.796$\\pm$0.045  0.807$\\pm$0.056   \n",
       "90%          F-1 score   SVM         0.814$\\pm$0.061  0.836$\\pm$0.027   \n",
       "                         LR          0.824$\\pm$0.057  0.834$\\pm$0.031   \n",
       "                         DCT         0.769$\\pm$0.093  0.786$\\pm$0.065   \n",
       "             sensitivity SVM         0.806$\\pm$0.093   0.85$\\pm$0.057   \n",
       "                         LR          0.804$\\pm$0.079  0.825$\\pm$0.054   \n",
       "                         DCT         0.744$\\pm$0.121  0.776$\\pm$0.107   \n",
       "\n",
       "                                             InsHard            OsImp  \n",
       "missing rate metric      classifier                                    \n",
       "50%          F-1 score   SVM         0.791$\\pm$0.041  0.899$\\pm$0.025  \n",
       "                         LR          0.778$\\pm$0.037   0.88$\\pm$0.034  \n",
       "                         DCT         0.758$\\pm$0.057  0.882$\\pm$0.037  \n",
       "             sensitivity SVM         0.742$\\pm$0.057  0.884$\\pm$0.032  \n",
       "                         LR           0.725$\\pm$0.05  0.859$\\pm$0.046  \n",
       "                         DCT         0.701$\\pm$0.073  0.879$\\pm$0.043  \n",
       "60%          F-1 score   SVM         0.784$\\pm$0.051  0.901$\\pm$0.022  \n",
       "                         LR          0.784$\\pm$0.042  0.872$\\pm$0.024  \n",
       "                         DCT         0.725$\\pm$0.082  0.889$\\pm$0.037  \n",
       "             sensitivity SVM         0.729$\\pm$0.072  0.885$\\pm$0.027  \n",
       "                         LR          0.728$\\pm$0.065  0.844$\\pm$0.038  \n",
       "                         DCT         0.659$\\pm$0.105  0.892$\\pm$0.031  \n",
       "70%          F-1 score   SVM          0.75$\\pm$0.054    0.88$\\pm$0.02  \n",
       "                         LR          0.747$\\pm$0.057  0.842$\\pm$0.045  \n",
       "                         DCT         0.687$\\pm$0.108  0.859$\\pm$0.031  \n",
       "             sensitivity SVM         0.686$\\pm$0.068  0.867$\\pm$0.024  \n",
       "                         LR          0.683$\\pm$0.072  0.807$\\pm$0.057  \n",
       "                         DCT          0.616$\\pm$0.13  0.856$\\pm$0.038  \n",
       "80%          F-1 score   SVM         0.738$\\pm$0.051  0.896$\\pm$0.026  \n",
       "                         LR          0.718$\\pm$0.063  0.848$\\pm$0.037  \n",
       "                         DCT         0.678$\\pm$0.121   0.83$\\pm$0.045  \n",
       "             sensitivity SVM          0.676$\\pm$0.06  0.888$\\pm$0.034  \n",
       "                         LR          0.653$\\pm$0.079  0.816$\\pm$0.048  \n",
       "                         DCT         0.619$\\pm$0.152  0.841$\\pm$0.052  \n",
       "90%          F-1 score   SVM         0.661$\\pm$0.184  0.853$\\pm$0.032  \n",
       "                         LR          0.621$\\pm$0.158  0.839$\\pm$0.033  \n",
       "                         DCT          0.68$\\pm$0.088  0.829$\\pm$0.071  \n",
       "             sensitivity SVM         0.613$\\pm$0.193  0.876$\\pm$0.028  \n",
       "                         LR          0.557$\\pm$0.168  0.827$\\pm$0.053  \n",
       "                         DCT         0.614$\\pm$0.104  0.819$\\pm$0.106  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftindex = pd.MultiIndex.from_product([[\"50%\", \"60%\", \"70%\", \"80%\", \"90%\"],\n",
    "                                        [\"F-1 score\",\"sensitivity\"], \n",
    "                                        [\"SVM\", \"LR\", \"DCT\"]], \n",
    "                                       names = [\"missing rate\", \"metric\", \"classifier\"])\n",
    "all_res = pd.DataFrame(concat_tab.to_numpy(), index = leftindex, columns = concat_tab.columns)\n",
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60280e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_to_export = pd.concat((res_all[0][0][0][0], res_all[0][0][0][1], \n",
    "                        res_all[1][0][0][0], res_all[1][0][0][1], \n",
    "                        res_all[2][0][0][0], res_all[2][0][0][1], \n",
    "                        res_all[3][0][0][0], res_all[3][0][0][1], \n",
    "                        res_all[4][0][0][0], res_all[4][0][0][1]))\n",
    "concat_to_export.to_csv(\"mean_f1_sensi_ecoli_high.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9712ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "    &             &     &         NearMiss &         kmeanSmt &            SmtNN &           SVMSmt &          InsHard &            OsImp \\\\\n",
      "missing rate & metric & classifier &                  &                  &                  &                  &                  &                  \\\\\n",
      "\\midrule\n",
      "50\\% & F-1 score & SVM &  0.627\\$\\textbackslash pm\\$0.085 &   0.885\\$\\textbackslash pm\\$0.02 &   0.866\\$\\textbackslash pm\\$0.03 &  0.894\\$\\textbackslash pm\\$0.032 &  0.791\\$\\textbackslash pm\\$0.041 &  0.899\\$\\textbackslash pm\\$0.025 \\\\\n",
      "    &             & LR &  0.792\\$\\textbackslash pm\\$0.071 &  0.856\\$\\textbackslash pm\\$0.022 &  0.827\\$\\textbackslash pm\\$0.036 &  0.882\\$\\textbackslash pm\\$0.027 &  0.778\\$\\textbackslash pm\\$0.037 &   0.88\\$\\textbackslash pm\\$0.034 \\\\\n",
      "    &             & DCT &  0.502\\$\\textbackslash pm\\$0.193 &  0.849\\$\\textbackslash pm\\$0.035 &  0.842\\$\\textbackslash pm\\$0.048 &  0.885\\$\\textbackslash pm\\$0.028 &  0.758\\$\\textbackslash pm\\$0.057 &  0.882\\$\\textbackslash pm\\$0.037 \\\\\n",
      "    & sensitivity & SVM &   0.55\\$\\textbackslash pm\\$0.091 &   0.87\\$\\textbackslash pm\\$0.028 &  0.841\\$\\textbackslash pm\\$0.037 &   0.882\\$\\textbackslash pm\\$0.04 &  0.742\\$\\textbackslash pm\\$0.057 &  0.884\\$\\textbackslash pm\\$0.032 \\\\\n",
      "    &             & LR &  0.746\\$\\textbackslash pm\\$0.087 &  0.827\\$\\textbackslash pm\\$0.029 &  0.789\\$\\textbackslash pm\\$0.049 &  0.862\\$\\textbackslash pm\\$0.036 &   0.725\\$\\textbackslash pm\\$0.05 &  0.859\\$\\textbackslash pm\\$0.046 \\\\\n",
      "    &             & DCT &   0.44\\$\\textbackslash pm\\$0.187 &  0.845\\$\\textbackslash pm\\$0.043 &  0.818\\$\\textbackslash pm\\$0.067 &  0.878\\$\\textbackslash pm\\$0.031 &  0.701\\$\\textbackslash pm\\$0.073 &  0.879\\$\\textbackslash pm\\$0.043 \\\\\n",
      "60\\% & F-1 score & SVM &   0.65\\$\\textbackslash pm\\$0.077 &  0.884\\$\\textbackslash pm\\$0.024 &  0.863\\$\\textbackslash pm\\$0.027 &  0.897\\$\\textbackslash pm\\$0.035 &  0.784\\$\\textbackslash pm\\$0.051 &  0.901\\$\\textbackslash pm\\$0.022 \\\\\n",
      "    &             & LR &  0.812\\$\\textbackslash pm\\$0.034 &  0.856\\$\\textbackslash pm\\$0.036 &  0.833\\$\\textbackslash pm\\$0.027 &  0.883\\$\\textbackslash pm\\$0.031 &  0.784\\$\\textbackslash pm\\$0.042 &  0.872\\$\\textbackslash pm\\$0.024 \\\\\n",
      "    &             & DCT &  0.528\\$\\textbackslash pm\\$0.231 &  0.868\\$\\textbackslash pm\\$0.038 &  0.824\\$\\textbackslash pm\\$0.043 &  0.872\\$\\textbackslash pm\\$0.047 &  0.725\\$\\textbackslash pm\\$0.082 &  0.889\\$\\textbackslash pm\\$0.037 \\\\\n",
      "    & sensitivity & SVM &  0.573\\$\\textbackslash pm\\$0.087 &  0.865\\$\\textbackslash pm\\$0.033 &  0.833\\$\\textbackslash pm\\$0.035 &  0.884\\$\\textbackslash pm\\$0.042 &  0.729\\$\\textbackslash pm\\$0.072 &  0.885\\$\\textbackslash pm\\$0.027 \\\\\n",
      "    &             & LR &  0.764\\$\\textbackslash pm\\$0.052 &   0.824\\$\\textbackslash pm\\$0.05 &  0.793\\$\\textbackslash pm\\$0.036 &  0.859\\$\\textbackslash pm\\$0.044 &  0.728\\$\\textbackslash pm\\$0.065 &  0.844\\$\\textbackslash pm\\$0.038 \\\\\n",
      "    &             & DCT &   0.477\\$\\textbackslash pm\\$0.22 &  0.867\\$\\textbackslash pm\\$0.029 &   0.791\\$\\textbackslash pm\\$0.06 &  0.864\\$\\textbackslash pm\\$0.047 &  0.659\\$\\textbackslash pm\\$0.105 &  0.892\\$\\textbackslash pm\\$0.031 \\\\\n",
      "70\\% & F-1 score & SVM &  0.666\\$\\textbackslash pm\\$0.069 &   0.83\\$\\textbackslash pm\\$0.029 &  0.835\\$\\textbackslash pm\\$0.019 &  0.855\\$\\textbackslash pm\\$0.024 &   0.75\\$\\textbackslash pm\\$0.054 &    0.88\\$\\textbackslash pm\\$0.02 \\\\\n",
      "    &             & LR &  0.783\\$\\textbackslash pm\\$0.038 &  0.821\\$\\textbackslash pm\\$0.026 &  0.799\\$\\textbackslash pm\\$0.031 &  0.857\\$\\textbackslash pm\\$0.031 &  0.747\\$\\textbackslash pm\\$0.057 &  0.842\\$\\textbackslash pm\\$0.045 \\\\\n",
      "    &             & DCT &  0.554\\$\\textbackslash pm\\$0.289 &  0.845\\$\\textbackslash pm\\$0.027 &  0.817\\$\\textbackslash pm\\$0.037 &  0.851\\$\\textbackslash pm\\$0.032 &  0.687\\$\\textbackslash pm\\$0.108 &  0.859\\$\\textbackslash pm\\$0.031 \\\\\n",
      "    & sensitivity & SVM &  0.589\\$\\textbackslash pm\\$0.076 &    0.8\\$\\textbackslash pm\\$0.035 &  0.796\\$\\textbackslash pm\\$0.024 &  0.836\\$\\textbackslash pm\\$0.033 &  0.686\\$\\textbackslash pm\\$0.068 &  0.867\\$\\textbackslash pm\\$0.024 \\\\\n",
      "    &             & LR &  0.727\\$\\textbackslash pm\\$0.049 &  0.779\\$\\textbackslash pm\\$0.032 &  0.748\\$\\textbackslash pm\\$0.039 &  0.827\\$\\textbackslash pm\\$0.037 &  0.683\\$\\textbackslash pm\\$0.072 &  0.807\\$\\textbackslash pm\\$0.057 \\\\\n",
      "    &             & DCT &  0.516\\$\\textbackslash pm\\$0.242 &  0.827\\$\\textbackslash pm\\$0.037 &   0.782\\$\\textbackslash pm\\$0.06 &   0.849\\$\\textbackslash pm\\$0.04 &   0.616\\$\\textbackslash pm\\$0.13 &  0.856\\$\\textbackslash pm\\$0.038 \\\\\n",
      "80\\% & F-1 score & SVM &  0.674\\$\\textbackslash pm\\$0.048 &  0.855\\$\\textbackslash pm\\$0.041 &  0.843\\$\\textbackslash pm\\$0.034 &   0.859\\$\\textbackslash pm\\$0.04 &  0.738\\$\\textbackslash pm\\$0.051 &  0.896\\$\\textbackslash pm\\$0.026 \\\\\n",
      "    &             & LR &  0.763\\$\\textbackslash pm\\$0.044 &  0.829\\$\\textbackslash pm\\$0.044 &  0.815\\$\\textbackslash pm\\$0.035 &  0.852\\$\\textbackslash pm\\$0.038 &  0.718\\$\\textbackslash pm\\$0.063 &  0.848\\$\\textbackslash pm\\$0.037 \\\\\n",
      "    &             & DCT &  0.372\\$\\textbackslash pm\\$0.213 &  0.836\\$\\textbackslash pm\\$0.056 &  0.816\\$\\textbackslash pm\\$0.033 &  0.817\\$\\textbackslash pm\\$0.048 &  0.678\\$\\textbackslash pm\\$0.121 &   0.83\\$\\textbackslash pm\\$0.045 \\\\\n",
      "    & sensitivity & SVM &  0.602\\$\\textbackslash pm\\$0.052 &  0.847\\$\\textbackslash pm\\$0.034 &   0.83\\$\\textbackslash pm\\$0.041 &  0.881\\$\\textbackslash pm\\$0.024 &   0.676\\$\\textbackslash pm\\$0.06 &  0.888\\$\\textbackslash pm\\$0.034 \\\\\n",
      "    &             & LR &  0.707\\$\\textbackslash pm\\$0.052 &   0.796\\$\\textbackslash pm\\$0.06 &  0.773\\$\\textbackslash pm\\$0.043 &  0.827\\$\\textbackslash pm\\$0.052 &  0.653\\$\\textbackslash pm\\$0.079 &  0.816\\$\\textbackslash pm\\$0.048 \\\\\n",
      "    &             & DCT &    0.34\\$\\textbackslash pm\\$0.16 &  0.822\\$\\textbackslash pm\\$0.059 &  0.796\\$\\textbackslash pm\\$0.045 &  0.807\\$\\textbackslash pm\\$0.056 &  0.619\\$\\textbackslash pm\\$0.152 &  0.841\\$\\textbackslash pm\\$0.052 \\\\\n",
      "90\\% & F-1 score & SVM &  0.684\\$\\textbackslash pm\\$0.097 &  0.833\\$\\textbackslash pm\\$0.028 &  0.814\\$\\textbackslash pm\\$0.061 &  0.836\\$\\textbackslash pm\\$0.027 &  0.661\\$\\textbackslash pm\\$0.184 &  0.853\\$\\textbackslash pm\\$0.032 \\\\\n",
      "    &             & LR &  0.705\\$\\textbackslash pm\\$0.107 &  0.802\\$\\textbackslash pm\\$0.021 &  0.824\\$\\textbackslash pm\\$0.057 &  0.834\\$\\textbackslash pm\\$0.031 &  0.621\\$\\textbackslash pm\\$0.158 &  0.839\\$\\textbackslash pm\\$0.033 \\\\\n",
      "    &             & DCT &  0.546\\$\\textbackslash pm\\$0.233 &   0.813\\$\\textbackslash pm\\$0.06 &  0.769\\$\\textbackslash pm\\$0.093 &  0.786\\$\\textbackslash pm\\$0.065 &   0.68\\$\\textbackslash pm\\$0.088 &  0.829\\$\\textbackslash pm\\$0.071 \\\\\n",
      "    & sensitivity & SVM &   0.618\\$\\textbackslash pm\\$0.11 &   0.84\\$\\textbackslash pm\\$0.053 &  0.806\\$\\textbackslash pm\\$0.093 &   0.85\\$\\textbackslash pm\\$0.057 &  0.613\\$\\textbackslash pm\\$0.193 &  0.876\\$\\textbackslash pm\\$0.028 \\\\\n",
      "    &             & LR &  0.644\\$\\textbackslash pm\\$0.121 &  0.782\\$\\textbackslash pm\\$0.046 &  0.804\\$\\textbackslash pm\\$0.079 &  0.825\\$\\textbackslash pm\\$0.054 &  0.557\\$\\textbackslash pm\\$0.168 &  0.827\\$\\textbackslash pm\\$0.053 \\\\\n",
      "    &             & DCT &  0.497\\$\\textbackslash pm\\$0.201 &  0.814\\$\\textbackslash pm\\$0.093 &  0.744\\$\\textbackslash pm\\$0.121 &  0.776\\$\\textbackslash pm\\$0.107 &  0.614\\$\\textbackslash pm\\$0.104 &  0.819\\$\\textbackslash pm\\$0.106 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_res.to_latex(index = True, \n",
    "                       formatters = {\"name\": str.upper},\n",
    "                      float_format = \"{.1f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfde6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
